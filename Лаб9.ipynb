{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Лаб9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPiCac/0XAHnPO+rXcOwobY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OlegLaiok/Comp_Lingv/blob/homework9/%D0%9B%D0%B0%D0%B19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EG5vWra0Ehb2",
        "outputId": "5ac2e8e5-17ba-4b8b-e4bf-8257493b2a02"
      },
      "source": [
        "!pip install natasha"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting natasha\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/8e/ab0745100be276750fb6b8858c6180a1756696572295a74eb5aea77f3bbd/natasha-1.4.0-py3-none-any.whl (34.4MB)\n",
            "\u001b[K     |████████████████████████████████| 34.4MB 117kB/s \n",
            "\u001b[?25hCollecting ipymarkup>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bf/9b/bf54c98d50735a4a7c84c71e92c5361730c878ebfe903d2c2d196ef66055/ipymarkup-0.9.0-py3-none-any.whl\n",
            "Collecting slovnet>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/3b/f1ef495be8990004959dd0510c95f688d1b07529f6a862bc56a405770b26/slovnet-0.5.0-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.2MB/s \n",
            "\u001b[?25hCollecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.8MB/s \n",
            "\u001b[?25hCollecting yargy>=0.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/46/bc1a17200a55f4b0608f39ac64f1840fd4a52f9eeea462d9afecbf71246b/yargy-0.15.0-py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.7MB/s \n",
            "\u001b[?25hCollecting razdel>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/15/2c/664223a3924aa6e70479f7d37220b3a658765b9cfe760b4af7ffdc50d38f/razdel-0.5.0-py3-none-any.whl\n",
            "Collecting navec>=0.9.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/c1/771ec5565f0ce24874d7fd325b429f9caa80517a40d2e4ce5705120591f3/navec-0.10.0-py3-none-any.whl\n",
            "Collecting intervaltree>=3\n",
            "  Downloading https://files.pythonhosted.org/packages/50/fb/396d568039d21344639db96d940d40eb62befe704ef849b27949ded5c3bb/intervaltree-3.1.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from slovnet>=0.3.0->natasha) (1.19.5)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 15.1MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.6.2)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
            "Building wheels for collected packages: intervaltree\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26120 sha256=1dce57e313945e53f465c1e4ddb57031892028996a774fbad5286c2e85dcfb18\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/f2/66/e9c30d3e9499e65ea2fa0d07c002e64de63bd0adaa49c445bf\n",
            "Successfully built intervaltree\n",
            "Installing collected packages: intervaltree, ipymarkup, navec, razdel, slovnet, pymorphy2-dicts-ru, dawg-python, pymorphy2, yargy, natasha\n",
            "  Found existing installation: intervaltree 2.1.0\n",
            "    Uninstalling intervaltree-2.1.0:\n",
            "      Successfully uninstalled intervaltree-2.1.0\n",
            "Successfully installed dawg-python-0.7.2 intervaltree-3.1.0 ipymarkup-0.9.0 natasha-1.4.0 navec-0.10.0 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 razdel-0.5.0 slovnet-0.5.0 yargy-0.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eROkrxDtEly2"
      },
      "source": [
        "import natasha\n",
        "import json\n",
        "import re\n",
        "import pandas as pd\n",
        "from natasha import Doc, Segmenter, NewsNERTagger, NewsEmbedding, NewsMorphTagger, MorphVocab\n",
        "import pymorphy2 \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import metrics\n",
        "from sklearn.cluster import KMeans\n",
        "analyzer = pymorphy2.MorphAnalyzer()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Gs3fgj5Ezuh",
        "outputId": "9b6f4209-30ec-4dcd-b473-b4d06d921ae2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlhtegROE0gQ"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/Colab Notebooks/VK_data_lentach_cleared.json\", \"r\", encoding ='utf-8') as f:\n",
        "    text = json.load(f)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsX5NUI9fYkF"
      },
      "source": [
        "Для выделения имменованных сущностей будем использовать тот же корпус новостей."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTdq_8voFDMy"
      },
      "source": [
        "embedding = NewsEmbedding() \n",
        "segmenter = Segmenter() # сегментация текста\n",
        "morph_tagger = NewsMorphTagger(embedding) #морфологический анализ для дальейшей лемматизации и выделения тэгов именованных сущностей\n",
        "morph_vocab = MorphVocab() \n",
        "ner_tagger = NewsNERTagger(embedding) #тэггер имменованных сущностей\n",
        "df = pd.DataFrame.from_dict({'text':text}) #создадим датафрейм, где будем хранить исходный текст, именнованные сущности и номера кластеров"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuHIctPBFFoC"
      },
      "source": [
        "def get_ner(transcript):\n",
        "  script = Doc(re.sub(r'\\((.*?)\\)', \"\", transcript))\n",
        "  script.segment(segmenter)\n",
        "  script.tag_morph(morph_tagger)\n",
        "  for token in script.tokens:\n",
        "    token.lemmatize(morph_vocab)\n",
        "  script.tag_ner(ner_tagger)\n",
        "  for span in script.spans:\n",
        "    span.normalize(morph_vocab)\n",
        "  named_ents = [(i.text, i.type, i.normal) for i in script.spans]\n",
        "  normed_ents = []\n",
        "  for word, tag, norm in named_ents:\n",
        "    if len(word.split()) == 1 and tag == \"LOC\":\n",
        "      for gram in range(len(analyzer.parse(word))):\n",
        "        if \"Geox\" in analyzer.parse(word)[gram].tag:\n",
        "          normed_ents.append((analyzer.parse(word)[gram].normal_form))\n",
        "          break\n",
        "        elif gram == len(analyzer.parse(word)) - 1:\n",
        "          normed_ents.append((norm.lower().strip(\".,!?;-\")))\n",
        "    else:\n",
        "      normed_ents.append((norm.lower().strip(\".,!?;-\")))\n",
        "  return sorted(normed_ents)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hu-rggygm1x"
      },
      "source": [
        "Следующая функция работает таким образом:\n",
        "1. текст сегментируется на токены\n",
        "2. на токены накладывается частеречная разметка\n",
        "4. токены лемматизируются\n",
        "5. выделяются именованные сущности\n",
        "6. токены нормализуются\n",
        "7. обрабатывается нормализация географических объектов, т.к. в процессе выяснилось, что natasha хуже их нормализует, чем pymorphy2.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4k0-yVvbTxZA",
        "outputId": "b46ada4a-7dc2-44c8-8354-9df99e545ba6"
      },
      "source": [
        "normed_ent = []\n",
        "for item in text:\n",
        "    normed_ent.append(get_ner(item)) # из текстовых данных выделяем именнованные сущность для каждого документа и записываем их в датафрейм\n",
        "df['named_entities'] = normed_ent\n",
        "has_ner = [i for i in df.index.values if df.named_entities[i]] #составляем список не пустых именнованных сущностей\n",
        "print(len(has_ner), df.shape[0]) # количество записей без пустых сущностей и с пустыми\n",
        "df_ner = df[df.index.isin(has_ner)] #создаем датафрейм где у каждого текстового документа обязательно есть не пустые имен. сущности\n",
        "ner_voc = []\n",
        "for row in df_ner.named_entities.tolist():\n",
        "  ner_voc.extend(row) \n",
        "len(ner_voc), len(set(ner_voc)) #количество всех сущностей в документе и количество уникальных сущностей"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "780 894\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2855, 1151)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFUpPcnwT27V"
      },
      "source": [
        "vocab = sorted(set(ner_voc)) #создаем словарь сущностей\n",
        "corpus = df_ner.named_entities.apply(str).tolist() #создаем корпус всех сущностей\n",
        "pipe = Pipeline([('count', CountVectorizer(vocabulary=vocab)),\n",
        "                 ('tfid', TfidfTransformer())]).fit(corpus) #создаем конвеер преобразований\n",
        "X = pipe.fit_transform(corpus) #применяем конвеер к корпусу"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2j4ZUqrqT7DY",
        "outputId": "acfe2c66-c93f-48ac-8dea-eae45451f793"
      },
      "source": [
        "km = KMeans(n_clusters=20, init='k-means++', max_iter=600, \n",
        "            algorithm=\"full\", precompute_distances=True) #обучаем класторизацию на корпусе\n",
        "km.fit(X) #применяем класторизацию к корпусу\n",
        "print('Силуэт: ', metrics.silhouette_score(X, km.labels_, sample_size=1000))\n",
        "print('Индекс Дэвиса-Болдуина: ', metrics.davies_bouldin_score(X.toarray(), km.labels_))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Силуэт:  0.13952876651282592\n",
            "Индекс Дэвиса-Болдуина:  1.9166579849583538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ULqJ38GkXyQ"
      },
      "source": [
        "Для нахождения оптимального количесва кластеров будем ориентироваться на метрики Силует и Индекс Девиса-Болдуина"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k16_IhufUBiD",
        "outputId": "7ffa93a6-b68b-4354-c22a-c7c08dc1bc75"
      },
      "source": [
        "km = KMeans(n_clusters=25, init='k-means++', max_iter=600, \n",
        "            algorithm=\"full\", precompute_distances=True)\n",
        "km.fit(X)\n",
        "print('Силуэт: ', metrics.silhouette_score(X, km.labels_, sample_size=1000))\n",
        "print('Индекс Дэвиса-Болдуина: ', metrics.davies_bouldin_score(X.toarray(), km.labels_))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Силуэт:  0.1484027072614288\n",
            "Индекс Дэвиса-Болдуина:  1.6406909399449683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-MXU9pCUF6P",
        "outputId": "14adfeef-a3cd-4fe4-b1f8-ce376a54c519"
      },
      "source": [
        "km = KMeans(n_clusters=30, init='k-means++', max_iter=600, \n",
        "            algorithm=\"full\", precompute_distances=True)\n",
        "km.fit(X)\n",
        "print('Силуэт: ', metrics.silhouette_score(X, km.labels_, sample_size=1000))\n",
        "print('Индекс Дэвиса-Болдуина: ', metrics.davies_bouldin_score(X.toarray(), km.labels_))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Силуэт:  0.16373586363757117\n",
            "Индекс Дэвиса-Болдуина:  1.737259414689813\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pSjZ1ztUUsJ",
        "outputId": "5a510227-49b8-43ec-ca66-f6258288cdd1"
      },
      "source": [
        "km = KMeans(n_clusters=35, init='k-means++', max_iter=600, \n",
        "            algorithm=\"full\", precompute_distances=True)\n",
        "km.fit(X)\n",
        "print('Силуэт: ', metrics.silhouette_score(X, km.labels_, sample_size=1000))\n",
        "print('Индекс Дэвиса-Болдуина: ', metrics.davies_bouldin_score(X.toarray(), km.labels_))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Силуэт:  0.17759318049812903\n",
            "Индекс Дэвиса-Болдуина:  1.6794265900769187\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXY3Xmu8klAt"
      },
      "source": [
        "Остановимся на 40 кластерах, т.к. дальше Силуэт очень медленно растет, а Индекс Девиса-Болдуина наоборот сильно начинает расти."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRfP5ZIXVBEX",
        "outputId": "07a766b9-6b36-47da-9754-a49c96d4266c"
      },
      "source": [
        "df_ner[\"label\"] = km.predict(X)\n",
        "print(df_ner[\"label\"].value_counts()) #посмотрим сколько объектов пинадлежит каждому классу"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1     459\n",
            "3      45\n",
            "18     27\n",
            "12     25\n",
            "11     23\n",
            "24     21\n",
            "5      16\n",
            "16     16\n",
            "25     13\n",
            "31     12\n",
            "8      12\n",
            "33     11\n",
            "34      9\n",
            "13      7\n",
            "14      7\n",
            "17      7\n",
            "26      7\n",
            "15      6\n",
            "27      6\n",
            "6       6\n",
            "30      5\n",
            "20      5\n",
            "28      5\n",
            "0       4\n",
            "21      4\n",
            "7       3\n",
            "29      3\n",
            "19      3\n",
            "10      3\n",
            "22      3\n",
            "2       2\n",
            "9       2\n",
            "23      1\n",
            "4       1\n",
            "32      1\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKmZ4ZMNlh9t"
      },
      "source": [
        "Заметим, что большое количесво объектов сгрупперовалось в первом кластере, скорее всего там находятся данные, которые алгоритм не смог определить в другие классы. Посмотрим примеры сущностей, содержащихся в этих статьях"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "3VkFTC9dlhJF",
        "outputId": "70fcc097-bf0b-4630-89b5-396b3a334430"
      },
      "source": [
        "df_ner.query(\"label == 1\").sample(10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>named_entities</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>655</th>\n",
              "      <td>Объявлены номинанты на «Оскар-2021»: Лучший фи...</td>\n",
              "      <td>[андра дэй, ванесса кирби, виола дэвис, гэри о...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>Måneskin — итальянская рок-группа, которая буд...</td>\n",
              "      <td>[måneskin, италия]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736</th>\n",
              "      <td>Министра здравоохранения Республики Алтай заде...</td>\n",
              "      <td>[республика алтай]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>Вечерняя сводка новостей по коронавирусу: Инди...</td>\n",
              "      <td>[regeneron pharmaceuticals, воз, зузана чапуто...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Кошка села на шею бабушке. В Ярославле появил...</td>\n",
              "      <td>[ярославль]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>В РЖД планируют привести все железнодорожные в...</td>\n",
              "      <td>[ржд]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>846</th>\n",
              "      <td>Журнал Time поместил на обложку основательниц...</td>\n",
              "      <td>[time, анна ривину, калининград, лувр, насилию...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>В Благовещенске бригада врачей провела операци...</td>\n",
              "      <td>[благовещенск, благовещенск]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>«Ведомости»: аптеки не хотят заниматься продаж...</td>\n",
              "      <td>[ведомости, минздрав]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>Хочешь рассмешить бога — расскажи ему о своих ...</td>\n",
              "      <td>[scmp, аргентина, китай, ковивак, минздрав, но...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  ... label\n",
              "655  Объявлены номинанты на «Оскар-2021»: Лучший фи...  ...     1\n",
              "395  Måneskin — итальянская рок-группа, которая буд...  ...     1\n",
              "736  Министра здравоохранения Республики Алтай заде...  ...     1\n",
              "94   Вечерняя сводка новостей по коронавирусу: Инди...  ...     1\n",
              "10    Кошка села на шею бабушке. В Ярославле появил...  ...     1\n",
              "765  В РЖД планируют привести все железнодорожные в...  ...     1\n",
              "846   Журнал Time поместил на обложку основательниц...  ...     1\n",
              "306  В Благовещенске бригада врачей провела операци...  ...     1\n",
              "83   «Ведомости»: аптеки не хотят заниматься продаж...  ...     1\n",
              "63   Хочешь рассмешить бога — расскажи ему о своих ...  ...     1\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNt48hCOmBhG"
      },
      "source": [
        "Видим, что тут содержатся документы имеющие нетипичные темы, поэтому кластеризация для них прошла не совсем корректно.\n",
        "Выведем получившиеся кластеры имменованных сущностей:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UNmA4KGVGN0",
        "outputId": "955f3893-d425-47dc-ae76-f59e4243611d"
      },
      "source": [
        "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
        "terms = pipe[0].get_feature_names()\n",
        "for i in range(35):\n",
        "  print(\"Cluster %d:\" % i, end='')\n",
        "  for ind in order_centroids[i, :10]:\n",
        "    print(' %s' % terms[ind], end='')\n",
        "  print()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cluster 0: европа еврокомиссия турция россия гонконг токио гамалея франция япония сми\n",
            "Cluster 1: россия astrazeneca турция воз германия сша франция ск беларусь ес\n",
            "Cluster 2: великобритания ярославль джон магуфули джастин трюдо джеймс кэмерон джек дорси джефф безос джимми хендрикс джо байден джордж флойд\n",
            "Cluster 3: петербург москва россия ярославль джастин трюдо джеймс кэмерон джек дорси джефф безос джимми хендрикс джо байден\n",
            "Cluster 4: aliexpress россия джон магуфули джастин трюдо джеймс кэмерон джек дорси джефф безос джимми хендрикс джо байден ярославль\n",
            "Cluster 5: москва россия маяковский каро благовещенск омон андрей мтс петербург казань\n",
            "Cluster 6: роскомнадзор восточный сми байден сша россия детская студия «дом свет джастин трюдо джеймс кэмерон джек дорси\n",
            "Cluster 7: it лужниках facebook дагестан госдума сми путин россия джимми хендрикс детская студия «дом свет\n",
            "Cluster 8: лентач голосовалка lumen кровосток dj пикчерами аукцыон главклуб clubhouse питер\n",
            "Cluster 9: париж ярославль джон магуфули джастин трюдо джеймс кэмерон джек дорси джефф безос джимми хендрикс джо байден джордж флойд\n",
            "Cluster 10: манижи ск совфед матвиенко россия дмитрий глуховского диана дзюба джордж флойд джон магуфули\n",
            "Cluster 11: сша россия эванстон штаты nbc tinder apple bloomberg венесуэла ссср\n",
            "Cluster 12: россия узбекистан фсб воз рф путин стокгольм сша подмосковье кндр\n",
            "Cluster 13: япония сенат astrazeneca лондон сми греция сша ямайка вакцинация интерфакс\n",
            "Cluster 14: вконтакте фсин челябинск youtube белгород маркл кровосток теннесси песняров upd\n",
            "Cluster 15: крым украина кнр тимошенко казахстан россия рф матвиенко меркель грузия\n",
            "Cluster 16: госдума россия реж известия эрмитаж ск нтв instagram генпрокуратура новосибирск\n",
            "Cluster 17: яндекс samsung минцифры downdetector сочи google youtube фсб госдума путин\n",
            "Cluster 18: сми upd белозерцев северодвинск химки нижневартовск макассар роналдо тайвань швеция\n",
            "Cluster 19: подмосковье ярославль джон магуфули джастин трюдо джеймс кэмерон джек дорси джефф безос джимми хендрикс джо байден джордж флойд\n",
            "Cluster 20: австралия свдс риви госдума джо байден госдепартамент джастин трюдо джеймс кэмерон джек дорси джефф безос\n",
            "Cluster 21: екатеринбург венеция ярославль джон магуфули джастин трюдо джеймс кэмерон джек дорси джефф безос джимми хендрикс джо байден\n",
            "Cluster 22: песков путин россия джимми хендрикс день пэйнта детская студия «дом свет джастин трюдо джеймс кэмерон джек дорси джефф безос\n",
            "Cluster 23: кемерово ярославль джон магуфули джастин трюдо джеймс кэмерон джек дорси джефф безос джимми хендрикс джо байден джордж флойд\n",
            "Cluster 24: навальный тасс покров сизо инстаграм сахарово tiktok мвд фбк россия\n",
            "Cluster 25: путин байден сша abc кремль мельниченко украина беларусь литва оон\n",
            "Cluster 26: китай воз chanel байден забайкалье сми bloomberg франция сша россия\n",
            "Cluster 27: сергей собянин ск госдума forbes bloomberg москва джордж флойд джон магуфули дзюба\n",
            "Cluster 28: петербург ярославль день пэйнта джастин трюдо джеймс кэмерон джек дорси джефф безос джимми хендрикс джо байден джон магуфули\n",
            "Cluster 29: испания россия джо байден детская студия «дом свет джастин трюдо джеймс кэмерон джек дорси джефф безос джимми хендрикс ярославль\n",
            "Cluster 30: telegram upd роскомнадзор телеграм mubadala дмитрий лисовец джастин трюдо джеймс кэмерон джек дорси джефф безос\n",
            "Cluster 31: рф россия минпросвещения минюст сша rt европа путин италия еспч\n",
            "Cluster 32: донбасс зеленский покров сми ярославль джо байден детская студия «дом свет джастин трюдо джеймс кэмерон джек дорси\n",
            "Cluster 33: twitter роскомнадзор захарова clubhouse ркн россия джеймс кэмерон джек дорси джефф безос джимми хендрикс\n",
            "Cluster 34: суд минск сми москва росгвардии фбк итмо каста политбюро сокольники\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTgwUe7imzaN"
      },
      "source": [
        "Не смотря на то, что кластеризация получилась не идеальная, в каждом кластере прослеживаются какие-то ключевые темы. Например какие-то кластеры будут содержать сущности из новостей про криминал (кластер 34), внешнюю политику(кластер 15), IT (кластер 33) и тд."
      ]
    }
  ]
}